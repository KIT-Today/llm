# ğŸ”¥ ë²ˆì•„ì›ƒ ê°ì§€ AI ì„œë²„ - ë°°í¬ ë° ìš´ì˜ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì‹œìŠ¤í…œ êµ¬ì¡°](#ì‹œìŠ¤í…œ-êµ¬ì¡°)
3. [ë¡œì»¬ ì‹¤í–‰ ë°©ë²•](#ë¡œì»¬-ì‹¤í–‰-ë°©ë²•)
4. [ì„œë²„ ë°°í¬ ë°©ë²•](#ì„œë²„-ë°°í¬-ë°©ë²•)
5. [API ëª…ì„¸](#api-ëª…ì„¸)
6. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
7. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

### ì´ ì„œë²„ê°€ í•˜ëŠ” ì¼
```
ì‚¬ìš©ì ì¼ê¸° í…ìŠ¤íŠ¸ â†’ ê°ì • ë¶„ì„ â†’ ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ â†’ ë§ì¶¤ í”¼ë“œë°± ìƒì„±
```

### í•µì‹¬ ê¸°ëŠ¥
| ê¸°ëŠ¥ | ì„¤ëª… |
|------|------|
| ê°ì • ë¶„ë¥˜ | ê¸ì •/ë¶€ì • â†’ 4ê°œ ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬ |
| í”¼ë“œë°± ìƒì„± | 5ê°€ì§€ í˜ë¥´ì†Œë‚˜ë³„ ë§ì¶¤ ë©”ì‹œì§€ |
| ë°±ì—”ë“œ ì—°ë™ | ë¹„ë™ê¸° ë¶„ì„ + ì½œë°± ì „ì†¡ |

### ì‚¬ìš© ê¸°ìˆ 
- **í”„ë ˆì„ì›Œí¬**: FastAPI (Python)
- **AI ëª¨ë¸**: KURE ì„ë² ë”© + PyTorch ë¶„ë¥˜ ëª¨ë¸
- **í”¼ë“œë°±**: í…œí”Œë¦¿ ê¸°ë°˜ (ë¹ ë¦„) / LLM ê¸°ë°˜ (ì„ íƒ)

---

## ì‹œìŠ¤í…œ êµ¬ì¡°

### ì „ì²´ ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   í”„ë¡ íŠ¸    â”‚ â”€â”€â–¶ â”‚   ë°±ì—”ë“œ    â”‚ â”€â”€â–¶ â”‚     AI ì„œë²„         â”‚
â”‚  (React)    â”‚     â”‚  (FastAPI)  â”‚     â”‚  (ì´ í”„ë¡œì íŠ¸)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                      â”‚
                           â–¼                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ PostgreSQL  â”‚     â”‚  KURE + Stage1/2    â”‚
                    â”‚     DB      â”‚     â”‚     AI ëª¨ë¸         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë¶„ì„ íë¦„
```
1. ì‚¬ìš©ìê°€ ì•±ì—ì„œ ì¼ê¸° ì‘ì„±
2. í”„ë¡ íŠ¸ â†’ ë°±ì—”ë“œ: ì¼ê¸° ì €ì¥ ìš”ì²­
3. ë°±ì—”ë“œ â†’ AI ì„œë²„: POST /analyze (ë¶„ì„ ìš”ì²­)
4. AI ì„œë²„: ì¦‰ì‹œ 200 OK ë°˜í™˜ (ë°±ì—”ë“œëŠ” ëŒ€ê¸° ì•ˆ í•¨)
5. AI ì„œë²„ ë°±ê·¸ë¼ìš´ë“œ:
   â”œâ”€â”€ KURE ì„ë² ë”© ìƒì„±
   â”œâ”€â”€ Stage 1: ê¸ì •/ë¶€ì • ë¶„ë¥˜
   â”œâ”€â”€ Stage 2: ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ë¶€ì •ì¼ ë•Œ)
   â””â”€â”€ í”¼ë“œë°± + ì†”ë£¨ì…˜ ì¶”ì²œ ìƒì„±
6. AI ì„œë²„ â†’ ë°±ì—”ë“œ: POST /diaries/analysis-callback (ê²°ê³¼ ì „ì†¡)
7. ë°±ì—”ë“œ: DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
8. ì•±ì—ì„œ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
```

### íŒŒì¼ êµ¬ì¡°
```
Burnout/
â”œâ”€â”€ ai_server.py          # ğŸ”¥ ë©”ì¸ ì„œë²„ (FastAPI)
â”œâ”€â”€ prompts.py            # í˜ë¥´ì†Œë‚˜ & í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”œâ”€â”€ explainer.py          # XAI ëª¨ë“ˆ (íŒë‹¨ ê·¼ê±° ì„¤ëª…)
â”œâ”€â”€ stage1_model.pt       # Stage 1 ëª¨ë¸ (ê¸ì •/ë¶€ì •)
â”œâ”€â”€ stage2_model.pt       # Stage 2 ëª¨ë¸ (4ê°œ ì¹´í…Œê³ ë¦¬)
â”œâ”€â”€ requirements.txt      # ì˜ì¡´ì„± ëª©ë¡
â”œâ”€â”€ .env.example          # í™˜ê²½ë³€ìˆ˜ ì˜ˆì‹œ
â”œâ”€â”€ README.md             # í”„ë¡œì íŠ¸ ì„¤ëª…
â””â”€â”€ test_burnout_full.py  # CLI í…ŒìŠ¤íŠ¸ ë„êµ¬
```

---

## ë¡œì»¬ ì‹¤í–‰ ë°©ë²•

### 1ë‹¨ê³„: ê°€ìƒí™˜ê²½ ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™
cd D:\Programming\Projects\Burnout

# ê°€ìƒí™˜ê²½ ìƒì„± (ìµœì´ˆ 1íšŒ)
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows PowerShell:
.\venv\Scripts\Activate.ps1
# Windows CMD:
.\venv\Scripts\activate.bat
# Linux/Mac:
source venv/bin/activate
```

### 2ë‹¨ê³„: ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt

# PyTorch GPU ë²„ì „ (CUDA 11.8 ê¸°ì¤€, ì„ íƒì‚¬í•­)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 3ë‹¨ê³„: í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ í¸ì§‘ (í•„ìš”ì‹œ)
```

### 4ë‹¨ê³„: ì„œë²„ ì‹¤í–‰
```bash
# ê°œë°œ ëª¨ë“œ (ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘)
uvicorn ai_server:app --reload --port 8001

# ë˜ëŠ” Pythonìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰
python ai_server.py
```

### 5ë‹¨ê³„: í…ŒìŠ¤íŠ¸
```bash
# ë¸Œë¼ìš°ì €ì—ì„œ Swagger UI ì—´ê¸°
http://localhost:8001/docs

# ì„œë²„ ìƒíƒœ í™•ì¸
http://localhost:8001/

# í˜ë¥´ì†Œë‚˜ ëª©ë¡ í™•ì¸
http://localhost:8001/personas
```

---

## ì„œë²„ ë°°í¬ ë°©ë²•

### ì˜µì…˜ 1: í´ë¼ìš°ë“œ VM (AWS EC2, GCP, Naver Cloud ë“±)

#### 1) ì„œë²„ ì ‘ì†
```bash
ssh username@ì„œë²„IP
```

#### 2) í”„ë¡œì íŠ¸ ì—…ë¡œë“œ
```bash
# ë°©ë²• A: Git ì‚¬ìš©
git clone [ë ˆí¬ì§€í† ë¦¬ URL]
cd Burnout

# ë°©ë²• B: íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ (scp)
scp -r ./Burnout username@ì„œë²„IP:/home/username/
```

#### 3) í™˜ê²½ ì„¤ì •
```bash
# Python ê°€ìƒí™˜ê²½
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
nano .env  # ë°±ì—”ë“œ URL ë“± ìˆ˜ì •
```

#### 4) í”„ë¡œë•ì…˜ ì‹¤í–‰
```bash
# Gunicorn + Uvicorn (ê¶Œì¥)
pip install gunicorn
gunicorn ai_server:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8001

# ë˜ëŠ” Uvicorn ì§ì ‘ (ê°„ë‹¨)
uvicorn ai_server:app --host 0.0.0.0 --port 8001 --workers 4
```

#### 5) ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ì„œë²„ ì¢…ë£Œí•´ë„ ìœ ì§€)
```bash
# ë°©ë²• A: nohup
nohup uvicorn ai_server:app --host 0.0.0.0 --port 8001 &

# ë°©ë²• B: screen
screen -S ai_server
uvicorn ai_server:app --host 0.0.0.0 --port 8001
# Ctrl+A, D ë¡œ detach

# ë°©ë²• C: systemd ì„œë¹„ìŠ¤ (ê¶Œì¥)
# /etc/systemd/system/ai-server.service íŒŒì¼ ìƒì„±
```

#### systemd ì„œë¹„ìŠ¤ íŒŒì¼ ì˜ˆì‹œ
```ini
# /etc/systemd/system/ai-server.service
[Unit]
Description=Burnout AI Server
After=network.target

[Service]
User=ubuntu
WorkingDirectory=/home/ubuntu/Burnout
Environment="PATH=/home/ubuntu/Burnout/venv/bin"
ExecStart=/home/ubuntu/Burnout/venv/bin/uvicorn ai_server:app --host 0.0.0.0 --port 8001
Restart=always

[Install]
WantedBy=multi-user.target
```

```bash
# ì„œë¹„ìŠ¤ ë“±ë¡ ë° ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl enable ai-server
sudo systemctl start ai-server
sudo systemctl status ai-server  # ìƒíƒœ í™•ì¸
```

### ì˜µì…˜ 2: Docker (ê¶Œì¥)

#### Dockerfile ìƒì„±
```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8001

# ì‹¤í–‰
CMD ["uvicorn", "ai_server:app", "--host", "0.0.0.0", "--port", "8001"]
```

#### Docker ë¹Œë“œ ë° ì‹¤í–‰
```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t burnout-ai-server .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d -p 8001:8001 --name ai-server burnout-ai-server

# ë¡œê·¸ í™•ì¸
docker logs -f ai-server
```

### ë°°í¬ í›„ í™•ì¸ì‚¬í•­

1. **ë°±ì—”ë“œ URL ì„¤ì •**
   ```
   BACKEND_CALLBACK_URL=http://ë°±ì—”ë“œì„œë²„IP:8000/diaries/analysis-callback
   ```

2. **ë°©í™”ë²½ ì„¤ì •**
   - 8001 í¬íŠ¸ ì—´ê¸°
   - ë°±ì—”ë“œ ì„œë²„ì—ì„œë§Œ ì ‘ê·¼ í—ˆìš© (ë³´ì•ˆ)

3. **í—¬ìŠ¤ì²´í¬**
   ```bash
   curl http://ì„œë²„IP:8001/health
   # {"status": "healthy"}
   ```

---

## API ëª…ì„¸

### ê¸°ë³¸ ì •ë³´
- **Base URL**: `http://ì„œë²„IP:8001`
- **Content-Type**: `application/json`

### ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡

#### `GET /` - ì„œë²„ ìƒíƒœ
```json
// Response
{
  "status": "running",
  "service": "Burnout Detection AI Server",
  "device": "cuda",  // ë˜ëŠ” "cpu"
  "model_loaded": true
}
```

#### `GET /health` - í—¬ìŠ¤ì²´í¬
```json
// Response
{"status": "healthy"}
```

#### `POST /analyze` - ë¶„ì„ ìš”ì²­ (ë©”ì¸ API)
```json
// Request
{
  "diary_id": 105,
  "user_id": 7,
  "history": [
    {
      "diary_id": 105,
      "content": "ì˜¤ëŠ˜ ìƒì‚¬í•œí…Œ ë˜ í˜¼ë‚¬ë‹¤. ë„ˆë¬´ ì–µìš¸í•˜ë‹¤.",
      "keywords": {"ê¸°ë¶„": "ë‚˜ì¨"},
      "created_at": "2026-01-30T12:00:00"
    }
  ]
}

// Response (ì¦‰ì‹œ ë°˜í™˜)
{
  "status": "accepted",
  "message": "ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
}

// ë¶„ì„ ì™„ë£Œ í›„ ë°±ì—”ë“œë¡œ ì½œë°± ì „ì†¡ë¨
```

#### `POST /analyze/sync` - ë™ê¸° ë¶„ì„ (í…ŒìŠ¤íŠ¸ìš©)
```json
// Request: /analyzeì™€ ë™ì¼

// Response (ë¶„ì„ ì™„ë£Œ í›„ ë°˜í™˜)
{
  "diary_id": 105,
  "primary_emotion": "ë¶€ì •",
  "primary_score": 0.92,
  "mbi_category": "FRUSTRATION_PRESSURE",
  "emotion_probs": {"ê¸ì •": 0.08, "ë¶€ì •": 0.92},
  "recommendations": [
    {
      "activity_id": 4,
      "ai_message": "ì–µìš¸í•œ ë§ˆìŒì´ ëŠê»´ì ¸ìš”. ì ì‹œ ê¹Šê²Œ ìˆ¨ì„ ì‰¬ì–´ë³´ì„¸ìš”."
    }
  ]
}
```

#### `GET /personas` - í˜ë¥´ì†Œë‚˜ ëª©ë¡
```json
// Response
{
  "personas": [
    {"type": "warm_counselor", "name": "ë”°ëœ»í•œ ìƒë‹´ì‚¬", "tone": "ë¶€ë“œëŸ½ê³  ë‹¤ì •í•œ"},
    {"type": "practical_advisor", "name": "ì‹¤ìš©ì  ì¡°ì–¸ì", "tone": "ì°¨ë¶„í•˜ê³  ëª…í™•í•œ"},
    {"type": "friendly_buddy", "name": "ì¹œê·¼í•œ ì¹œêµ¬", "tone": "í¸í•˜ê³  ì¹œê·¼í•œ"},
    {"type": "calm_mentor", "name": "ì°¨ë¶„í•œ ë©˜í† ", "tone": "ë‹´ë‹´í•˜ê³  ê¹Šì´ ìˆëŠ”"},
    {"type": "cheerful_supporter", "name": "ë°ì€ ì‘ì›ë‹¨", "tone": "ë°ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ”"}
  ]
}
```

#### `POST /test/feedback` - í”¼ë“œë°± í…ŒìŠ¤íŠ¸
```
// Query Parameters
- category: ì •ì„œì _ê³ ê°ˆ, ì¢Œì ˆ_ì••ë°•, ë¶€ì •ì _ëŒ€ì¸ê´€ê³„, ìê¸°ë¹„í•˜, ê¸ì •
- text: í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸
- persona: warm_counselor, practical_advisor, friendly_buddy, calm_mentor, cheerful_supporter

// Example
POST /test/feedback?category=ì¢Œì ˆ_ì••ë°•&text=ìƒì‚¬ê°€í™”ë¥¼ëƒˆë‹¤&persona=friendly_buddy

// Response
{
  "category": "ì¢Œì ˆ_ì••ë°•",
  "persona": {
    "type": "friendly_buddy",
    "name": "ì¹œê·¼í•œ ì¹œêµ¬",
    "tone": "í¸í•˜ê³  ì¹œê·¼í•œ"
  },
  "feedback": "í—, ì§„ì§œ ì—´ë°›ì•˜ê² ë‹¤. ë‚˜ë¼ë„ í™”ë‚¬ì„ ë“¯."
}
```

---

## í™˜ê²½ ì„¤ì •

### .env íŒŒì¼ ì„¤ì •

```bash
# ë°±ì—”ë“œ ì½œë°± URL (í•„ìˆ˜)
BACKEND_CALLBACK_URL=http://ë°±ì—”ë“œì„œë²„:8000/diaries/analysis-callback

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
MODEL_DIR=.

# LLM ì‚¬ìš© ì—¬ë¶€ (false: í…œí”Œë¦¿, true: KoAlpaca)
USE_LLM=false

# ê¸°ë³¸ í˜ë¥´ì†Œë‚˜
DEFAULT_PERSONA=warm_counselor

# ì„œë²„ ì„¤ì •
PORT=8001
HOST=0.0.0.0
```

### í™˜ê²½ë³„ ì„¤ì • ì˜ˆì‹œ

#### ê°œë°œ (ë¡œì»¬)
```bash
BACKEND_CALLBACK_URL=http://127.0.0.1:8000/diaries/analysis-callback
USE_LLM=false
```

#### ìŠ¤í…Œì´ì§•
```bash
BACKEND_CALLBACK_URL=http://staging-backend.example.com/diaries/analysis-callback
USE_LLM=false
```

#### í”„ë¡œë•ì…˜
```bash
BACKEND_CALLBACK_URL=http://api.example.com/diaries/analysis-callback
USE_LLM=true  # GPU ì„œë²„ì¸ ê²½ìš°
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

#### 1. ëª¨ë“ˆ import ì—ëŸ¬
```
ERROR: Could not import module "ai_server"
```
**í•´ê²°**: ë°˜ë“œì‹œ `Burnout` í´ë” ì•ˆì—ì„œ ì‹¤í–‰
```bash
cd D:\Programming\Projects\Burnout
uvicorn ai_server:app --reload --port 8001
```

#### 2. ëª¨ë¸ íŒŒì¼ ì—†ìŒ
```
FileNotFoundError: stage1_model.pt
```
**í•´ê²°**: ëª¨ë¸ íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸
```bash
ls *.pt  # stage1_model.pt, stage2_model.pt ìˆì–´ì•¼ í•¨
```

#### 3. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```
RuntimeError: CUDA out of memory
```
**í•´ê²°**: CPU ëª¨ë“œë¡œ ì‹¤í–‰í•˜ê±°ë‚˜ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
```bash
# CPU ê°•ì œ ì‚¬ìš©
CUDA_VISIBLE_DEVICES="" uvicorn ai_server:app --port 8001
```

#### 4. ì½œë°± ì „ì†¡ ì‹¤íŒ¨
```
âŒ ì½œë°± ì „ì†¡ ì—ëŸ¬: Connection refused
```
**í•´ê²°**: ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, URLì´ ë§ëŠ”ì§€ í™•ì¸
```bash
curl http://ë°±ì—”ë“œURL/health  # ë°±ì—”ë“œ ìƒíƒœ í™•ì¸
```

#### 5. PowerShellì—ì„œ curl ì—ëŸ¬
```
Invoke-WebRequest : ë§¤ê°œ ë³€ìˆ˜ ì´ë¦„ 'X'ê³¼(ì™€) ì¼ì¹˜í•˜ëŠ” ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
```
**í•´ê²°**: `curl.exe` ì‚¬ìš© ë˜ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ `/docs` ì ‘ì†
```powershell
curl.exe -X POST "http://localhost:8001/test/feedback"
# ë˜ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8001/docs
```

---

## ì—°ë½ì²˜

- **AI ë‹´ë‹¹**: ì¡°ë¯¼ì„±
- **í”„ë¡œì íŠ¸**: í•œêµ­í˜• ë²ˆì•„ì›ƒ ê°ì§€ ì•± (ì˜¤ëŠ˜ë„)

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2026-01-30*
