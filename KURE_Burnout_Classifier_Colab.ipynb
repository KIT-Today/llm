{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ KURE ê¸°ë°˜ í•œêµ­í˜• ë²ˆì•„ì›ƒ ê°ì • ë¶„ë¥˜ ëª¨ë¸\n",
        "\n",
        "**ëª¨ë¸ êµ¬ì¡°**: KURE ì„ë² ë”© (1024ì°¨ì›) + ë¶„ë¥˜ í—¤ë“œ â†’ 4ê°œ ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬\n",
        "\n",
        "**ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬**:\n",
        "- 0: ì •ì„œì _ê³ ê°ˆ (ì—ë„ˆì§€ ì†Œì§„, í”¼ë¡œ, ë¬´ë ¥ê°)\n",
        "- 1: ì¢Œì ˆ_ì••ë°• (ë¶„ë…¸, ë¶ˆë§Œ, ì–µìš¸í•¨)\n",
        "- 2: ë¶€ì •ì _ëŒ€ì¸ê´€ê³„ (ëŒ€ì¸ ê°ˆë“±, ì†Œì™¸ê°)\n",
        "- 3: ìê¸°ë¹„í•˜ (ë¶ˆì•ˆ, ìì±…, ìˆ˜ì¹˜ì‹¬)"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. í™˜ê²½ ì„¤ì •"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q sentence-transformers transformers torch pandas scikit-learn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import os\n",
        "\n",
        "# GPU í™•ì¸\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ–¥ï¸ Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬ ì •ì˜"
      ],
      "metadata": {
        "id": "categories-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë²ˆì•„ì›ƒ ì¹´í…Œê³ ë¦¬\n",
        "BURNOUT_CATEGORIES = {\n",
        "    0: \"ì •ì„œì _ê³ ê°ˆ\",\n",
        "    1: \"ì¢Œì ˆ_ì••ë°•\",\n",
        "    2: \"ë¶€ì •ì _ëŒ€ì¸ê´€ê³„\",\n",
        "    3: \"ìê¸°ë¹„í•˜\"\n",
        "}\n",
        "\n",
        "# ê°ì • â†’ ë²ˆì•„ì›ƒ ë§¤í•‘\n",
        "EMOTION_TO_BURNOUT = {\n",
        "    # ì •ì„œì  ê³ ê°ˆ (0)\n",
        "    \"ìŠ¤íŠ¸ë ˆìŠ¤\": 0, \"ë¬´ë ¥í•¨\": 0, \"ê³µí—ˆí•¨\": 0, \"ë‹µë‹µí•¨\": 0,\n",
        "    \"ë¶€ë‹´\": 0, \"ì§€ë£¨í•¨\": 0, \"ê·€ì°®ìŒ\": 0, \"í›„íšŒ\": 0, \"ì™¸ë¡œì›€\": 0,\n",
        "    \"í”¼ê³¤\": 0, \"ì§€ì¹¨\": 0, \"ë¬´ê¸°ë ¥\": 0, \"ìš°ìš¸\": 0, \"ìŠ¬í””\": 0,\n",
        "\n",
        "    # ì¢Œì ˆ/ì••ë°• (1)\n",
        "    \"ì–µìš¸\": 1, \"ë¶ˆë§Œ\": 1, \"ì›ë§\": 1, \"ë¶„ë…¸\": 1, \"ë¶ˆí‰\": 1,\n",
        "    \"ë¶ˆí¸í•¨\": 1, \"ë¶ˆì¾Œ\": 1, \"ì§ˆíˆ¬\": 1, \"ë‹¹í™©\": 1, \"í™”ë‚¨\": 1, \"ì§œì¦\": 1,\n",
        "\n",
        "    # ë¶€ì •ì  ëŒ€ì¸ê´€ê³„ (2)\n",
        "    \"ê°ˆë“±\": 2, \"ë°°ì‹ \": 2, \"ë¬´ì‹œ\": 2, \"ì†Œì™¸\": 2, \"ì„œìš´í•¨\": 2,\n",
        "\n",
        "    # ìê¸°ë¹„í•˜ (3)\n",
        "    \"ë¶ˆì•ˆ\": 3, \"ê±±ì •\": 3, \"ì´ˆì¡°\": 3, \"ìê´´ê°\": 3, \"ì£„ì±…ê°\": 3,\n",
        "    \"í˜¼ë€í•¨\": 3, \"ë‘ë ¤ì›€\": 3, \"ë¶€ë„ëŸ¬ì›€\": 3, \"ìì±…\": 3,\n",
        "}\n",
        "\n",
        "print(\"âœ“ ì¹´í…Œê³ ë¦¬ ì •ì˜ ì™„ë£Œ\")"
      ],
      "metadata": {
        "id": "categories"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ëª¨ë¸ ì •ì˜"
      ],
      "metadata": {
        "id": "model-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KUREEmbeddingLayer(nn.Module):\n",
        "    \"\"\"KURE ì„ë² ë”© ë ˆì´ì–´ (1024ì°¨ì›)\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"nlpai-lab/KURE-v1\", freeze_encoder=True, device=None):\n",
        "        super().__init__()\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"ğŸ“¥ Loading KURE model: {model_name}\")\n",
        "        print(\"   (ì²« ì‹¤í–‰ ì‹œ ~2GB ë‹¤ìš´ë¡œë“œ, ëª‡ ë¶„ ì†Œìš”)\")\n",
        "\n",
        "        self.encoder = SentenceTransformer(model_name, device=self.device)\n",
        "        self.embedding_dim = self.encoder.get_sentence_embedding_dimension()\n",
        "\n",
        "        print(f\"âœ“ Embedding dimension: {self.embedding_dim}\")\n",
        "\n",
        "        if freeze_encoder:\n",
        "            for param in self.encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"âœ“ Encoder frozen\")\n",
        "\n",
        "    def forward(self, texts: List[str]) -> torch.Tensor:\n",
        "        return self.encoder.encode(texts, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "\n",
        "class BurnoutClassificationHead(nn.Module):\n",
        "    \"\"\"ë¶„ë¥˜ í—¤ë“œ\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=1024, hidden_dim=256, num_classes=4, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        return self.classifier(embeddings)\n",
        "\n",
        "\n",
        "class KUREBurnoutClassifier(nn.Module):\n",
        "    \"\"\"KURE + ë¶„ë¥˜ í—¤ë“œ ì „ì²´ ëª¨ë¸\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"nlpai-lab/KURE-v1\", hidden_dim=256,\n",
        "                 num_classes=4, dropout=0.3, freeze_encoder=True, device=None):\n",
        "        super().__init__()\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.embedding_layer = KUREEmbeddingLayer(\n",
        "            model_name=model_name,\n",
        "            freeze_encoder=freeze_encoder,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        self.classification_head = BurnoutClassificationHead(\n",
        "            input_dim=self.embedding_layer.embedding_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_classes=num_classes,\n",
        "            dropout=dropout\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, texts: List[str]):\n",
        "        embeddings = self.embedding_layer(texts)\n",
        "        return self.classification_head(embeddings)\n",
        "\n",
        "    def predict(self, texts: List[str]):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.forward(texts)\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            labels = torch.argmax(logits, dim=-1).cpu().tolist()\n",
        "            categories = [BURNOUT_CATEGORIES[l] for l in labels]\n",
        "        return labels, categories, probs\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save({\n",
        "            'classification_head': self.classification_head.state_dict(),\n",
        "            'num_classes': self.num_classes\n",
        "        }, path)\n",
        "        print(f\"âœ“ Saved to {path}\")\n",
        "\n",
        "    def load_model(self, path):\n",
        "        ckpt = torch.load(path, map_location=self.device)\n",
        "        self.classification_head.load_state_dict(ckpt['classification_head'])\n",
        "        print(f\"âœ“ Loaded from {path}\")\n",
        "\n",
        "print(\"âœ“ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ë°ì´í„°ì…‹ & í•™ìŠµ í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "dataset-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BurnoutDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'text': self.texts[idx], 'label': self.labels[idx]}\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    texts = [item['text'] for item in batch]\n",
        "    labels = torch.tensor([item['label'] for item in batch], dtype=torch.long)\n",
        "    return {'texts': texts, 'labels': labels}\n",
        "\n",
        "\n",
        "def train_model(model, train_dataset, val_dataset=None, epochs=10,\n",
        "                batch_size=16, learning_rate=2e-4):\n",
        "    \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "    device = model.device\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = None\n",
        "    if val_dataset:\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.classification_head.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for batch in pbar:\n",
        "            texts = batch['texts']\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(texts)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        history['train_loss'].append(avg_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "\n",
        "        # Validation\n",
        "        val_acc = 0\n",
        "        if val_loader:\n",
        "            model.eval()\n",
        "            val_correct, val_total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    texts = batch['texts']\n",
        "                    labels = batch['labels'].to(device)\n",
        "                    logits = model(texts)\n",
        "                    _, predicted = torch.max(logits, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "            history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"  Loss: {avg_loss:.4f} | Train Acc: {train_acc:.1f}% | Val Acc: {val_acc:.1f}%\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "print(\"âœ“ ë°ì´í„°ì…‹ & í•™ìŠµ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ],
      "metadata": {
        "id": "training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ìƒ˜í”Œ ë°ì´í„° ìƒì„±"
      ],
      "metadata": {
        "id": "sample-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_data():\n",
        "    \"\"\"í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°\"\"\"\n",
        "    train_texts = [\n",
        "        # ì •ì„œì  ê³ ê°ˆ (0)\n",
        "        \"ì˜¤ëŠ˜ë„ ì•¼ê·¼í–ˆë‹¤. ë„ˆë¬´ ì§€ì¹œë‹¤.\",\n",
        "        \"ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ê³  ë¬´ë ¥í•˜ë‹¤.\",\n",
        "        \"ë§¤ì¼ ë°˜ë³µë˜ëŠ” ì¼ìƒì´ ì§€ê²¹ë‹¤.\",\n",
        "        \"ì—ë„ˆì§€ê°€ ë°”ë‹¥ë‚¬ë‹¤.\",\n",
        "        \"ì‰¬ì–´ë„ í”¼ë¡œê°€ ì•ˆ í’€ë¦°ë‹¤.\",\n",
        "        \"ì¼í•˜ê¸° ì‹«ì€ë° í•´ì•¼ í•œë‹¤.\",\n",
        "        \"ë²ˆì•„ì›ƒì´ ì˜¨ ê²ƒ ê°™ë‹¤.\",\n",
        "        \"ëª¸ë„ ë§ˆìŒë„ ì§€ì³ìˆë‹¤.\",\n",
        "\n",
        "        # ì¢Œì ˆ/ì••ë°• (1)\n",
        "        \"ìƒì‚¬ì—ê²Œ ë˜ ê¹¨ì¡Œë‹¤. ì–µìš¸í•˜ë‹¤.\",\n",
        "        \"ë…¸ë ¥í•´ë„ ì¸ì •ë°›ì§€ ëª»í•œë‹¤.\",\n",
        "        \"ë¶ˆí•©ë¦¬í•œ ì§€ì‹œì— í™”ê°€ ë‚œë‹¤.\",\n",
        "        \"ì„±ê³¼ë¥¼ ê°€ë¡œì±„ì—¬ì„œ ë¶„í•˜ë‹¤.\",\n",
        "        \"ì••ë°•ê°ì— ìˆ¨ì´ ë§‰íŒë‹¤.\",\n",
        "        \"ì§„ì§œ ì§œì¦ë‚˜ëŠ” í•˜ë£¨ì˜€ë‹¤.\",\n",
        "        \"ì™œ ë‚˜ë§Œ ì´ëŸ° ì¼ì„ ë‹¹í•´ì•¼ í•˜ì§€.\",\n",
        "        \"ë¶ˆê³µí‰í•´ì„œ ë¯¸ì¹  ê²ƒ ê°™ë‹¤.\",\n",
        "\n",
        "        # ë¶€ì •ì  ëŒ€ì¸ê´€ê³„ (2)\n",
        "        \"ë™ë£Œë“¤ì´ ë‚˜ë¥¼ ë”°ëŒë¦¬ëŠ” ê²ƒ ê°™ë‹¤.\",\n",
        "        \"íŒ€ ë¶„ìœ„ê¸°ê°€ ë„ˆë¬´ ì•ˆ ì¢‹ë‹¤.\",\n",
        "        \"ì‚¬ëŒë“¤ê³¼ ëŒ€í™”í•˜ê¸° ì‹«ë‹¤.\",\n",
        "        \"ì§ì¥ ë‚´ ê°ˆë“±ìœ¼ë¡œ í˜ë“¤ë‹¤.\",\n",
        "        \"ìƒì‚¬ì™€ì˜ ê´€ê³„ê°€ ìµœì•…ì´ë‹¤.\",\n",
        "        \"ì•„ë¬´ë„ ë‚´ í¸ì´ ì—†ëŠ” ê²ƒ ê°™ë‹¤.\",\n",
        "        \"ì‚¬ë‚´ ì •ì¹˜ì— ì§€ì³¤ë‹¤.\",\n",
        "        \"ë™ë£Œì—ê²Œ ë°°ì‹ ë‹¹í•œ ê¸°ë¶„ì´ë‹¤.\",\n",
        "\n",
        "        # ìê¸°ë¹„í•˜ (3)\n",
        "        \"ë‚˜ëŠ” ëŠ¥ë ¥ì´ ì—†ëŠ” ê²ƒ ê°™ë‹¤.\",\n",
        "        \"ì‹¤ìˆ˜í• ê¹Œë´ ë¶ˆì•ˆí•˜ë‹¤.\",\n",
        "        \"ë‹¤ë¥¸ ì‚¬ëŒë“¤ë³´ë‹¤ ëª»í•œ ê²ƒ ê°™ë‹¤.\",\n",
        "        \"ìì‹ ê°ì´ ë°”ë‹¥ì´ë‹¤.\",\n",
        "        \"ì´ëŸ° ë‚˜ ìì‹ ì´ ë¶€ë„ëŸ½ë‹¤.\",\n",
        "        \"ë‚´ê°€ ì˜í•  ìˆ˜ ìˆì„ê¹Œ ê±±ì •ëœë‹¤.\",\n",
        "        \"ìê¾¸ ì‹¤ìˆ˜í•´ì„œ ìì±…í•˜ê²Œ ëœë‹¤.\",\n",
        "        \"ë‚˜ë§Œ ë’¤ì²˜ì§€ëŠ” ê²ƒ ê°™ë‹¤.\",\n",
        "    ]\n",
        "\n",
        "    train_labels = [0]*8 + [1]*8 + [2]*8 + [3]*8\n",
        "    return train_texts, train_labels\n",
        "\n",
        "train_texts, train_labels = create_sample_data()\n",
        "print(f\"âœ“ ìƒ˜í”Œ ë°ì´í„°: {len(train_texts)}ê°œ\")\n",
        "print(f\"  - ì •ì„œì _ê³ ê°ˆ: 8ê°œ\")\n",
        "print(f\"  - ì¢Œì ˆ_ì••ë°•: 8ê°œ\")\n",
        "print(f\"  - ë¶€ì •ì _ëŒ€ì¸ê´€ê³„: 8ê°œ\")\n",
        "print(f\"  - ìê¸°ë¹„í•˜: 8ê°œ\")"
      ],
      "metadata": {
        "id": "sample-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. ëª¨ë¸ í•™ìŠµ ğŸš€"
      ],
      "metadata": {
        "id": "train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸš€ ëª¨ë¸ ì´ˆê¸°í™”\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "model = KUREBurnoutClassifier(\n",
        "    model_name=\"nlpai-lab/KURE-v1\",\n",
        "    hidden_dim=256,\n",
        "    num_classes=4,\n",
        "    dropout=0.3,\n",
        "    freeze_encoder=True\n",
        ")"
      ],
      "metadata": {
        "id": "init-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ“š ëª¨ë¸ í•™ìŠµ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "train_dataset = BurnoutDataset(train_texts, train_labels)\n",
        "\n",
        "model, history = train_model(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    epochs=10,\n",
        "    batch_size=8,\n",
        "    learning_rate=1e-3\n",
        ")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "test-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ”® ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_texts = [\n",
        "    \"ì˜¤ëŠ˜ ì •ë§ í”¼ê³¤í•˜ë‹¤. ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´.\",\n",
        "    \"ìƒì‚¬ê°€ ë˜ ë¬´ë¦¬í•œ ìš”êµ¬ë¥¼ í–ˆë‹¤. ì—´ë°›ì•„.\",\n",
        "    \"íŒ€ì›ë“¤ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ ì†ìƒí•˜ë‹¤.\",\n",
        "    \"ë°œí‘œë¥¼ ì•ë‘ê³  ë„ˆë¬´ ë¶ˆì•ˆí•˜ë‹¤. ì˜í•  ìˆ˜ ìˆì„ê¹Œ.\",\n",
        "    \"íšŒì‚¬ ë‹¤ë‹ˆê¸° ì‹«ì€ë° ëˆì€ ë²Œì–´ì•¼ í•˜ê³ ...\",\n",
        "]\n",
        "\n",
        "labels, categories, probs = model.predict(test_texts)\n",
        "\n",
        "for i, (text, cat, prob) in enumerate(zip(test_texts, categories, probs)):\n",
        "    print(f\"\\n[{i+1}] {text}\")\n",
        "    print(f\"    â†’ ì˜ˆì¸¡: {cat}\")\n",
        "    prob_dict = {name: f\"{p:.1%}\" for name, p in zip(BURNOUT_CATEGORIES.values(), prob.cpu().numpy())}\n",
        "    print(f\"    â†’ í™•ë¥ : {prob_dict}\")"
      ],
      "metadata": {
        "id": "test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. ëª¨ë¸ ì €ì¥ (ì„ íƒ)"
      ],
      "metadata": {
        "id": "save-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive ë§ˆìš´íŠ¸ (ì„ íƒ)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "# model.save_model('/content/drive/MyDrive/burnout_model.pt')\n",
        "\n",
        "# ë¡œì»¬ ì €ì¥\n",
        "model.save_model('burnout_model.pt')"
      ],
      "metadata": {
        "id": "save"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "custom-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§ì ‘ ë¬¸ì¥ ì…ë ¥í•´ì„œ í…ŒìŠ¤íŠ¸\n",
        "my_text = \"ì›”ìš”ì¼ ì•„ì¹¨ë¶€í„° ì•¼ê·¼ ì˜ˆê³ ë¥¼ ë°›ì•˜ë‹¤. ë²Œì¨ ì§€ì¹œë‹¤.\"  # @param {type:\"string\"}\n",
        "\n",
        "labels, categories, probs = model.predict([my_text])\n",
        "\n",
        "print(f\"\\nì…ë ¥: {my_text}\")\n",
        "print(f\"\\nğŸ·ï¸ ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬: {categories[0]}\")\n",
        "print(f\"\\nğŸ“Š í™•ë¥  ë¶„í¬:\")\n",
        "for name, p in zip(BURNOUT_CATEGORIES.values(), probs[0].cpu().numpy()):\n",
        "    bar = \"â–ˆ\" * int(p * 20)\n",
        "    print(f\"  {name}: {bar} {p:.1%}\")"
      ],
      "metadata": {
        "id": "custom-test"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
